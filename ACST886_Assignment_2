---
title: "ACST886_Assignment2_Q1"
author: "Chieh Cheng"
date: "September 3, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Q1
There are 3 possible estimates for $q_{30}$.
###Part 1: Estimate $q_{30}$ without assuming Binomial or Poisson:  
__Step 1: Insuring age__  
_Method:_ Define a vector "Age_ins" for the insuring age. Create a new numeric vector "temp" for storing dates of latest birthday just before policies issued. Suppose they are the Xth birthday of each individual. If time span between "temp" and policy issued date is greater than 182 days (i.e.half years), then the insuring age for that individual should be X+1, otherwise X it is.  
```{r}
library(lubridate)
num_Birth <- c(19640317,19640506,19640812,
               19641027,19650104,19650418,
               19650520,19650704,19650916,19651211)
num_Issued <- c(19920620,19920806,19921218,
                19930104,19930428,19930616,
                19931029,19940216,19940822,19950306)
num_Death <- c(NA,19930612,NA,NA,19960829,
               NA,19960421,NA,NA,19970217)
num_Withdrawal <- c(NA,NA,19950618,NA,NA,
                     19951212,NA,NA,19970222,NA)
Birth<-ymd(num_Birth)
Issued<-ymd(num_Issued)
Death<-ymd(num_Death)
Withdrawal<-ymd(num_Withdrawal)

# Function SPAN calculates the time difference between date1 & date2
SPAN<-function(date1, date2){
  Interval<-interval(date1, date2)
  return(as.period(Interval))
}

#temp stores the dates of birthday just before the policy issued date:
temp <- num_Birth + SPAN(Birth,Issued)$year*10000
Age_ins<-c()   #Stores the "insuring age"
for(i in 1:10){Age_ins[i]<-ifelse(difftime(Issued[i],ymd(temp[i]))>182,                                    
                                  SPAN(Birth,Issued)$year[i]+1,
                                  SPAN(Birth,Issued)$year[i])}
M<-matrix(Age_ins);colnames(M)<-"Age_ins"
as.table(M)  
```  
  
__Step 2: Withdrawal age (calendar insuring age)__   
_Method:_ Create vecter "Age_W", "Year_W", "Year_B" for withdrawal age, calendar year of withdrawal, and valuation year of birth, then  
$$Age\_W = Year\_W - Year\_B$$  
```{r}
Year_W<-year(Withdrawal)
Year_B<-year(Issued)-Age_ins
Age_W<-Year_W - Year_B
M<-matrix(Age_W);colnames(M)<-"Age_W"
as.table(M)  
```  

__Step 3: Calculate exposed to risk vector "E_x" __  
__Method:__ __3.1 Find Data A and Date B mentioned in the week 2 lecture notes.__    
Date A is the latest of the date reaching age label 30, the start of the overall investigation, and the date of entry into the population.  
Date B is the earliest of the date reaching age label 31, the end of the overall investigation, and the date of exit from the population for whatever the reason.  
  
Also, I create a indicator vector "Indicator_d30". If the individual died in insuring age 30, the value is 1. Otherwise it is zero. It will be used when I build the likelihood function.

```{r}
Indicator_d30 <- rep(0,10)
####################################################
Date_A<-pmax(num_Issued+(30-Age_ins)*10000,
             1993*10000+month(Issued)*100+day(Issued),
             num_Issued)
# If the above Date_A is after the death date, then Date_A doesn't exist for that individual: 
Date_A[which(Date_A>num_Death)]<-NA
####################################################################
Date_B<-pmin(num_Issued+(31-Age_ins)*10000,
             1998*10000+month(Issued)*100+day(Issued))
#1. If there is no Date_A for that person, then Date_B should be marked as NA as well.
#2. Adjust Date_B if the date of exit for death or withdrawal is the earliest.
for(i in 1:10){
  if(is.na(Date_A[i])){
    Date_B[i]<-NA
  }else if(!is.na(num_Death[i]) && num_Death[i]>Date_A[i] && num_Death[i]<Date_A[i]+1*10000){
  Date_B[i] <- num_Death[i]
  Indicator_d30[i] <- 1    #The person died in the insuring age 30
  }
}
Date_B[which(Age_W==30)] <- Date_A[which(Age_W==30)]
#Summarize Date_A & Date_B
M<-matrix(c(Date_A,Date_B),ncol = 2);colnames(M)<-c("Date_A","Date_B")
as.table(M)
```  
__3.2 Find "E_x" based on Date_A & Date_B __    
```{r}
E_x<-rep(0,10)
for(i in 1:10){
  if(is.na(Date_A[i])){
    E_x[i] <- 0
  }else{
    E_x[i] <- as.numeric(difftime(ymd(Date_B[i]),ymd(Date_A[i])))/365.25
    #avoid 365 & 366 problem: Assume E_x[i] to be 1 rather than 365/365.25
    if(Date_B[i]-Date_A[i]==10000){E_x[i] <- 1} 
  }
}
M<-matrix(E_x,ncol=1);colnames(M)<-"E_x";as.table(M)
```  
__Step 4: Find MLE of $q_{30}$ under constant force of mortality __  
```{r}
OBJ<-function(q){
  obj<-1
  for(i in 1:10){
    if(Indicator_d30[i]==1){
      obj<-obj*(1-(1-q)^E_x[i])
    }else{
      obj<-obj*(1-q)^E_x[i]
    }
  }
  return(-obj)
}
nlminb(start = 0.5,objective = OBJ,lower=0)
```   
__Part 1 Conclusion: __  
The $q_{30}$ estimate is around __0.2585__.  

###Part 2: Under Binomial Model:  
Simply find d30 and Initial Exposed to Risk vector "Ex_binom".
_Method:_ From Part 1, d30 here equals to the number of non-zero-or-one values in E_x. Also, set all those non-zero-or-one values to 1 and then sum over whole E_x, we obtain intial exposed to risk.  
```{r}
d30<-length(which(!((E_x==1)|(E_x==0)))) 
Ex_binom<-E_x
Ex_binom[which(!((E_x==1)|(E_x==0)))]=1
q30_binom<-d30/sum(Ex_binom)
```  
__Part 2 Conclusion: __  
the $q_{30}$ estimate under Binomial Model is exactly __0.25__. 
  
###Part 3: Under Poisson Model:  
If we treat the last line of the question as Poisson Model settings, then we have to calculate central exposed to risk vector "Ex_Poisson". Fortunately, this is exactly the vector"E_x".
```{r}
Ex_Poisson <- E_x
mu_Poisson <- d30/sum(Ex_Poisson)
q30 <- 1 - exp(-mu_Poisson) 
``` 
__Part 3 Conclusion:__   
Under Poisson model, the $\mu$ estimate is about 0.2691103 and the $q_{30}$ estimate is around 0.23594.  



##Q2  
__Step 1: Initial setting & Graphical check __
```{r}
Age<-c(42,47,52,57,62,67,72,77,82,87,92)
Ex<-c(15518,19428,21594,21890,19174,15775,11414,6993,3276,1096,201)
dx <- c(65,144,219,378,465,557,685,644,471,217,67)
Exp_dx<-c(73.9,134.6,223.9,346.3,468.1,600.2,675.5,637.4,458.7,240.6,61.4)
qx <- dx/Ex 
grad_qx<-Exp_dx/Ex
Exqx<-Exp_dx
var_dx <- Ex * grad_qx * (1- grad_qx)
zx <- (dx - Exqx)/sqrt(var_dx)

#Plot
library(ggplot2)
ggplot()+
  geom_point(data = data.frame(Age,qx),mapping = aes(x=Age,y=qx))+
  geom_line(data = data.frame(Age,grad_qx),mapping = aes(x=Age,y=grad_qx))
```    
__Observation: __ Since there are only 11 data points, the smoothness needs to be checked. Also, there are larger differences between actual data and graduated data in the age groups above 80.
  
__Step 2: Check Smoothness __
```{r}
diff_1 <- grad_qx[2:length(grad_qx)] - grad_qx[1:(length(grad_qx)-1)]
diff_2 <- diff_1[2:length(diff_1)] - diff_1[1:(length(diff_1)-1)]
diff_3 <- diff_2[2:length(diff_2)] - diff_2[1:(length(diff_2)-1)]
Smoothness<-ifelse(abs(diff_3)*7^3<grad_qx[1:length(diff_3)],"GOOD","BAD")
#bad! 
```  
__Step 2 Conclusion: __ This graduated curve isn't smooth in the sense of the third difference.  
__Step 3 Chi_Square Test: __
```{r}
T_Chi_Square <- sum(zx^2)
Critical_Chi_Square <- qchisq(0.95,11:5)
```   
__Step 3 Conclusion: __ As long as the number of parameters estimated is less than or equal to 11-6=5, then we have insufficient evidence to reject H0. In other words, the adherence of the graduated data is accepted.  

__Step 4 Standardised Deviation Test: __
```{r}
#Divided zx into 4 groups: (-Inf,-1),(-1,0),(0,1),(1,Inf)
threshold<-c(-Inf,-1,0,1,Inf)
A<-rep(0,4);E<-rep(0,4)
for(i in 1:4){
  A[i]<-sum((zx>threshold[i])*(zx<threshold[i+1]))
  E[i]<-length(zx)*(pnorm(threshold[i+1])-pnorm(threshold[i]))
}
T_Stand_Dev <- sum((A-E)^2/E) 
Critial_Stand_Dev<-qchisq(0.95,4-1)
#since test statistic is 2.45 which is less than the critical value, the adherence of the graduation is good.
```  
Cumulative Deviation Test:
```{r}
T_Cumulativ_Dev <- sum(dx-Exqx)/sqrt(sum(var_dx))
#Since the absolute value of the test statistic is less then 1.96, the adherence of the graduated data is good.
```  
Sign Test:
```{r}
T_sign <- sum(zx>0)
k<-qbinom(0.025,length(zx),0.5)
# Since T=6 is between k=2 and length(zx)-k=9, the adherence of adherence is good.
```  
Grouping of sign test:
```{r}
T_Group_Sign<-0
for(i in 2:length(zx)){
  if(zx[i]*zx[i-1]<0){T_Group_Sign = T_Group_Sign + 1}
}
n1 <- length(which(zx>0))
n2 <- length(which(zx<0))
obj=0;j=1
while(obj<0.05){
  obj = obj + choose(n1-1,j-1)*choose(n2+1,j)/choose(n1+n2,n1) 
  j=j+1
}
Critical_Group_Sign=j
# Since T=7 is greater then the critical value 3, the adherence of the graduated data is good.
```  
Serial Correlation Test
```{r}
zbar_1<-mean(zx[1:(length(zx)-1)])
zbar_2<-mean(zx[2:length(zx)])
corr_serial<-sum((zx[1:(length(zx)-1)]-zbar_1)*(zx[2:length(zx)]-zbar_2))/sqrt(sum((zx[1:(length(zx)-1)]-zbar_1)^2)*sum((zx[2:length(zx)]-zbar_2)^2))
T_Serial_Corr <- (corr_serial - 0)/sqrt(1/(length(zx)-1))
#Since the absolute value of test statistic is less then 1.64, we conclude that the adherence graduated data is good.
```  

##Q3
5.7
```{r}
Age<-70:75
Ecx<-c(1000,1005,1010,1008,1006,998)
dx<-c(80,90,95,105,115,125)
mux<-dx/Ecx
#Objective function: -loglikelihood
OBJ<-function(para){
  -sum(log(exp(-Ecx*para[1]*para[2]^Age)*(Ecx*para[1]*para[2]^Age)^dx/factorial(dx)))
}
OBJ1<-function(para){
  abs(sum(-Ecx*para[2]^Age + dx/para[1]))+abs(sum(-Ecx*para[1]*Age*para[2]^(Age-1)+Age*dx/para[2]))
}
#Find appropriate intial estimates for B & C:
mod_ini <- lm(log(mux)~Age,data = data.frame(mux,Age)) 
Ini_est <- c(exp(mod_ini$coefficients[1]),exp(mod_ini$coefficients[2])) 
MLE<-nlm(OBJ,Ini_est)$estimate
grad_mux<-MLE[1]*MLE[2]^Age
library(ggplot2)
ggplot()+
  geom_point(data=data.frame(Age,mux),mapping = aes(x=Age,y=mux))+
  geom_smooth(data=data.frame(Age,grad_mux),mapping = aes(x=Age,y=grad_mux))
```   

5.8  
```{r}
Age <- 30:49
Ex <- c(70000,66672,68375,65420,61779,66091,68514,69560,65000,66279,67300,65368,65391,62917,66537,62302,62145,63856,61097,61110)
dx <- c(39,43,34,31,23,50,48,43,48,47,62,63,84,86,120,121,122,162,151,184)
qx <- dx/Ex
logit_qx <- log(qx/(1-qx))
OBJ <- function(para){
  sum(Ex*(logit_qx-(para[1]+para[2]*Age))^2)
}
Ini_est<-lm(logit_qx~Age,data = data.frame(Age,logit_qx))$coefficients
WLS<-nlm(OBJ,Ini_est,steptol = 10^-10)$estimate
grad_qx<-exp(WLS[1]+WLS[2]*Age)/(1+exp(WLS[1]+WLS[2]*Age))
#plot
library(ggplot2)
ggplot()+
  geom_point(data=data.frame(Age,qx),mapping = aes(x=Age,y=qx))+
  geom_point(data=data.frame(Age,grad_qx),mapping = aes(x=Age,y=grad_qx),color="red")+
  geom_smooth(data=data.frame(Age,grad_qx),mapping = aes(x=Age,y=grad_qx))
```  
  
5.9
```{r}
Age <- 47:67
Ex <- c(166,187,218,243,276,302,347,390,430,494,558,628,701,813,917,1040,1182,1299,1432,1596,1752)
dx <- c(2,2,4,6,2,4,7,3,9,9,8,11,14,18,18,24,30,43,41,54,64)
qSx <- c(0.00505,0.0057,0.00644,0.00728,0.00826,0.0093,0.01051,0.01184,0.01331,0.01492,0.01668,0.01859,0.02065,0.02287,0.02525,0.02778,0.03049,0.03339,0.03648,0.03978,0.04332) 
qx <- dx/Ex
OBJ <- function(para){
  sum(Ex*(qx-(para[1]+para[2]*qSx))^2)
}
Ini_est<-lm(qx~qSx,data = data.frame(qx,qSx))$coefficients
WLS<-nlm(OBJ,Ini_est)$estimate
grad_qx<-WLS[1] + WLS[2] * qSx 
#plot 
library(ggplot2)
ggplot()+
  geom_point(data=data.frame(Age,qx),mapping = aes(x=Age,y=qx))+
  geom_point(data=data.frame(Age,grad_qx),mapping = aes(x=Age,y=grad_qx),color="red")+
  geom_smooth(data=data.frame(Age,grad_qx),mapping = aes(x=Age,y=grad_qx))
```



